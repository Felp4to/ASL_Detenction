{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow opencv-python mediapipe matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import yaml\n",
    "import shutil\n",
    "import constants as cs\n",
    "import globali as gg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:40:30.410723300Z",
     "start_time": "2024-05-31T08:40:20.684453500Z"
    }
   },
   "id": "732807148be4b4c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def read_yaml_fields():\n",
    "    with open(cs.YAMLFILE, 'r') as ff:\n",
    "        content = yaml.safe_load(ff)\n",
    "        a = set(content.get('actions', []))\n",
    "        c = content.get('counter', {})\n",
    "        return a, c\n",
    "\n",
    "def update_yaml_fields(new_actions, new_counter):\n",
    "    with open(cs.YAMLFILE, 'r') as ff:\n",
    "        content = yaml.safe_load(ff)\n",
    "    content['actions'] = new_actions\n",
    "    content['counter'] = new_counter\n",
    "    with open(cs.YAMLFILE, 'w') as ff:\n",
    "        yaml.safe_dump(content, ff)\n",
    "        \n",
    "def reset_yaml_fields():\n",
    "    current_timestamp_time = time.time()\n",
    "    file_name, file_extension = os.path.splitext(cs.YAMLFILE)\n",
    "    destination = (\"backups/\" +\n",
    "                   file_name + \"_\" +\n",
    "                   str(current_timestamp_time) +\n",
    "                   file_extension)\n",
    "    shutil.copy(cs.YAMLFILE, destination)\n",
    "    content = {'actions': set(), 'counter': {}}\n",
    "    with open(cs.YAMLFILE, 'w') as ff:\n",
    "        yaml.safe_dump(content, ff)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:40:30.429863800Z",
     "start_time": "2024-05-31T08:40:30.421594800Z"
    }
   },
   "id": "60859c33890e0365"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# reset_yaml_fields()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:40:30.459838400Z",
     "start_time": "2024-05-31T08:40:30.430868600Z"
    }
   },
   "id": "ac35a8261c0d7b45"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:40:30.479997200Z",
     "start_time": "2024-05-31T08:40:30.449466900Z"
    }
   },
   "id": "c19f40d0e604a3f4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)      # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                       # Image is no longer writeable\n",
    "    results = model.process(image)                      # Make prediction\n",
    "    image.flags.writeable = True                        # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)      # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    \n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:40:30.515423800Z",
     "start_time": "2024-05-31T08:40:30.485004900Z"
    }
   },
   "id": "23540904ce7052c8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# function that erase content videos' folder\n",
    "def clean_folder():\n",
    "    for file in os.listdir(cs.VIDEOS_FOLDER):\n",
    "        file_path = os.path.join(cs.VIDEOS_FOLDER, file)\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "            #print\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:40:30.516433800Z",
     "start_time": "2024-05-31T08:40:30.494850700Z"
    }
   },
   "id": "4b5012f1b7c6aad2"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "clean_folder()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:40:30.673113500Z",
     "start_time": "2024-05-31T08:40:30.515423800Z"
    }
   },
   "id": "941814dbf688bfb0"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "def collect_data(action, no_sequences, no_frames, time_record, signer, camId):\n",
    "    gg.actions, gg.counters = read_yaml_fields()\n",
    "    \n",
    "    if action not in gg.actions:\n",
    "        gg.counters[action] = 0\n",
    "    \n",
    "    action_folder = os.path.join(cs.KEYPOINTS_FOLDER, action)\n",
    "    os.makedirs(action_folder, exist_ok=True)\n",
    "    action_folder2 = os.path.join(cs.VIDEOS_FOLDER, action)\n",
    "    os.makedirs(action_folder2, exist_ok=True)\n",
    "    gg.actions.add(action)\n",
    "    \n",
    "    # clean folder videos\n",
    "    clean_folder()\n",
    "    \n",
    "    cap = cv2.VideoCapture(camId)\n",
    "    \n",
    "    # Set mediapipe model \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        \n",
    "        for sequence in range(no_sequences):\n",
    "            \n",
    "            video_folder = os.path.join(action_folder, str(gg.counters[action] + sequence))\n",
    "            os.makedirs(video_folder, exist_ok=True)\n",
    "            video_folder2 = os.path.join(action_folder2, str(gg.counters[action] + sequence))\n",
    "            os.makedirs(video_folder2, exist_ok=True)\n",
    "            \n",
    "            for frame_num in range(no_frames):\n",
    "                \n",
    "                ret, frame = cap.read()                                                 # Read feed\n",
    "                image, results = mediapipe_detection(frame, holistic)                   # Make detections\n",
    "                draw_styled_landmarks(image, results)                                   # Draw landmarks     \n",
    "                \n",
    "                num = gg.counters[action] + sequence\n",
    "                frame_path = os.path.join(cs.VIDEOS_FOLDER, action, str(num), str(frame_num) + \".jpg\")\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "                \n",
    "                if frame_num == 0: \n",
    "                    cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(time_record)\n",
    "                else:\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                \n",
    "                keypoints = extract_keypoints(results)\n",
    "                \n",
    "                npy_path = os.path.join(video_folder, str(frame_num))\n",
    "                # npy_path = os.path.join(video_folder, str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "                \n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                \n",
    "        # update actions and counters\n",
    "        gg.counters[action] += no_sequences\n",
    "        update_yaml_fields(gg.actions, gg.counters)\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T08:40:30.716338200Z",
     "start_time": "2024-05-31T08:40:30.677052600Z"
    }
   },
   "id": "9dbf23d52db2f143"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "words = ['zero', 'uno', 'due', 'tre', 'quattro', 'cinque', 'sei', 'sette', 'otto', 'nove',\n",
    "         'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i','j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'z', 'x', 'w', 'y', \n",
    "         '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''\n",
    "         ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T09:24:59.648623500Z",
     "start_time": "2024-05-31T09:24:59.646406500Z"
    }
   },
   "id": "fef953970771b768"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "collect_data(words[26], 50, cs.NUM_FRAME, 2000, \"paolo\", 1)                        # 26 Q"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T09:14:54.464323400Z",
     "start_time": "2024-05-31T09:11:06.216727300Z"
    }
   },
   "id": "2b33a93648f869bc"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'a',\n 'b',\n 'c',\n 'cinque',\n 'd',\n 'due',\n 'e',\n 'f',\n 'g',\n 'h',\n 'i',\n 'j',\n 'k',\n 'l',\n 'm',\n 'nove',\n 'otto',\n 'quattro',\n 'sei',\n 'sette',\n 'tre',\n 'uno',\n 'zero'}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg.actions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T21:53:29.095364900Z",
     "start_time": "2024-05-27T21:53:29.068024700Z"
    }
   },
   "id": "8e5d967853c54b8c"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "100"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg.counters[(\"p\")]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-31T09:06:31.019592600Z",
     "start_time": "2024-05-31T09:06:31.010398600Z"
    }
   },
   "id": "f957ca3e5c75a8bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e08fee4be363602"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "61487caec662b30c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
